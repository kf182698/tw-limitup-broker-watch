"""Fetch and parse the limit-up (æ¼²åœ) list from the configured source."""

from typing import Optional, Any
import pandas as pd
from io import StringIO
from datetime import date
# å‡è¨­æ‚¨åœ¨ src/app/utils_http ä¸­æœ‰ requests ç›¸é—œçš„å°å…¥
import requests 


class LimitUpListError(Exception):
    """Base exception for limit-up list fetching and parsing errors."""
    pass


def fetch_limitup_html(url: str) -> str:
    """Fetch the HTML from the given limit-up list URL.

    The caller must provide a fully qualified URL. Handles response encoding.
    Raises LimitUpListError on network failure.
    """
    try:
        # å‡è¨­ get_session æä¾›äº†æ­£ç¢ºçš„ Session ç‰©ä»¶
        sess = get_session() 
        resp = sess.get(url, timeout=20)
        resp.raise_for_status()  # æª¢æŸ¥ HTTP éŒ¯èª¤
        
        # è¨­ç½®ç·¨ç¢¼ï¼šä½¿ç”¨ä¼ºæœå™¨/Apparentï¼Œæœ€çµ‚å›é€€åˆ° UTF-8
        resp.encoding = resp.encoding or resp.apparent_encoding or "utf-8"
        
        return resp.text
    except requests.exceptions.RequestException as e:
        raise LimitUpListError(f"Network error fetching limit-up list from {url}: {e}")


def parse_limitup_table(html: str, trade_date: str) -> pd.DataFrame:
    """Parse the first table in the HTML as a limit-up list.

    The resulting DataFrame will always contain these columns: trade_date, 
    code, stock_name, market, close, volume, pct_change.
    Raises LimitUpListError if no tables can be parsed.
    """
    # -------------------------------------------------------------
    # ğŸ¯ ä¿®å¾© Pandas FutureWarningï¼šä½¿ç”¨ StringIO
    # -------------------------------------------------------------
    try:
        tables = pd.read_html(StringIO(html)) 
    except Exception as e:
        # é€™è£¡æœƒæ•æ‰åˆ°æˆ‘å€‘ä¸Šæ¬¡çœ‹åˆ°çš„ lxml éŒ¯èª¤ï¼Œä¸¦æ‹‹å‡ºæ¸…æ™°çš„éŒ¯èª¤è¨Šæ¯
        raise LimitUpListError(f"Failed to parse HTML tables: {e}")
        
    if not tables:
        raise LimitUpListError("No tables found in the HTML content.")
        
    df = tables[0].copy()
    
    # æ¬„ä½æ˜ å°„
    rename_map = {}
    standard_columns = {
        "stock_name": ["è‚¡ç¥¨", "åç¨±", "è­‰åˆ¸"],
        "code": ["ä»£è™Ÿ", "è‚¡ç¥¨ä»£è™Ÿ"],
        "close": ["æ”¶ç›¤", "åƒ¹æ ¼"],
        "volume": ["æˆäº¤", "é‡", "è‚¡"],
        "pct_change": ["æ¼²è·Œ", "%", "å¹…åº¦"],
    }

    for col in df.columns:
        col_str = str(col).strip()
        for std_name, keywords in standard_columns.items():
            if any(k in col_str for k in keywords):
                rename_map[col] = std_name
                break
                
    df = df.rename(columns=rename_map)

    # æ•¸æ“šæ¸…æ´—èˆ‡é¡å‹è½‰æ›
    numeric_cols = ["pct_change", "close", "volume"]
    for col in numeric_cols:
        if col in df.columns:
            # ç§»é™¤é€—è™Ÿå’Œç™¾åˆ†è™Ÿï¼Œç„¶å¾Œè½‰æ›ç‚ºæ•¸å­—
            df[col] = df[col].astype(str).str.replace(r'[^\d\.\-]', '', regex=True) 
            df[col] = pd.to_numeric(df[col], errors="coerce")

    # ç¢ºä¿æœ€çµ‚ DataFrame çµæ§‹å®Œæ•´
    result = pd.DataFrame()
    
    # -------------------------------------------------------------
    # ğŸ¯ éŒ¯èª¤ä¿®æ­£ï¼šç§»é™¤ .strftime()ï¼Œç›´æ¥ä½¿ç”¨ trade_date (å®ƒå·²ç¶“æ˜¯å­—ä¸²)
    # -------------------------------------------------------------
    result["trade_date"] = trade_date # <-- ä¿®æ­£å¾Œçš„ç¨‹å¼ç¢¼ (å–ä»£ç¬¬ 83 è¡Œ)
    
    result["code"] = df.get("code", pd.Series(dtype=str)).astype(str).str.strip()
    result["stock_name"] = df.get("stock_name", pd.Series(dtype=str)).astype(str).str.strip()
    result["market"] = None # ä¿æŒç‚º Noneï¼Œç­‰å¾…å¾ŒçºŒåˆ¤æ–· (å¦‚ TPEX, TAI)
    result["close"] = df.get("close")
    result["volume"] = df.get("volume")
    result["pct_change"] = df.get("pct_change")
    
    # åˆªé™¤ code æˆ– pct_change ç‚ºç©ºçš„è¡Œ
    result = result.dropna(subset=["code", "pct_change"])

    return result


def build_limitup_list(trade_date: date, limitup_url: str, min_pct: float) -> Optional[pd.DataFrame]:
    """
    Main function to execute the fetching, parsing, and filtering pipeline.
    
    Args:
        trade_date: The trading date (should be a datetime.date object for consistency).
        limitup_url: The URL to fetch the data from.
        min_pct: The minimum percentage change to qualify as limit-up.
        
    Returns:
        DataFrame of limit-up stocks, or None if the process fails.
    """
    try:
        # æ³¨æ„ï¼šé›–ç„¶ parse_limitup_table æ¥æ”¶å­—ä¸²ï¼Œä½†ç‚ºäº†ä¿æŒé¡å‹ä¸€è‡´æ€§ï¼Œ
        # æˆ‘å€‘åœ¨é€™è£¡å°‡ trade_date æ ¼å¼åŒ–ç‚ºå­—ä¸²å†å‚³éã€‚
        trade_date_str = trade_date.strftime("%Y-%m-%d")
        
        html = fetch_limitup_html(limitup_url)
        df = parse_limitup_table(html, trade_date_str)
        
        # ç¯©é¸å‡ºæ¼²åœè‚¡ç¥¨ (ç¢ºä¿ pct_change å­˜åœ¨ä¸”å¤§æ–¼ç­‰æ–¼ min_pct)
        if df.empty or "pct_change" not in df.columns:
            return None
            
        limitup_df = df[df["pct_change"] >= min_pct]
        
        return limitup_df
        
    except LimitUpListError as e:
        print(f"Error in limit-up list pipeline: {e}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None
